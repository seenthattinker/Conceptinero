IMPORTANT: Use existing materials and documents generated during your development work to extract the pertinent information to complete these questions.

242 – What technological obstacles did you have to overcome? 350 words max – 50 lines of 78 characters
The state of technology at the beginning of the project had several shortcomings and/or limitations, as well as technological problems and unknown elements, as described below:

Web AR/VR for Sitecore
We continued extending the capabilities of the Sitecore content management system to include the facets of Virtual and Augmented Reality that results in increased customer experience in editing and authoring content. The Sitecore industry has no instances of available design or architectures to base our initial approach on, as we needed to develop a scalable VR/AR architecture that would work seamlessly within Sitecore’s technology footprint. It was uncertain on how to extend Sitecore native API and add new API libraries to bring the AR/VR technologies within the same Sitecore architecture and leveraging the content management features of the core product. We were not sure how to extend website tools and capability to be able to launch the application, platform independent (Windows, iOS, Android) and device independent (desktop/laptop, iPad, and smartphone). We were challenged on how to best develop Sitecore API components to generate 3D images / views, navigation hotspots within the VR/AR environment so that content could be authored to work within those components without taking additional content authoring steps. 

Web AR Feature Detection
Another major challenge is the enabling natural feature detection in Web AR. We could do image recognition using marker-based detection AR, but not the location-based AR. While testing prototypes for marker-based detection AR, we were constrained with performance and storage limitations due to the way the 3D images were processed. We had to store a number of 3D images at high resolution and also access them based on the detection algorithm. We were also experimenting the model with IoT devices to see if that would provide a better AR and VR experience. However, during the testing process, we were hit with the network bandwidth limitation. The existing 4G network didn’t provide enough bandwidth to load images within 2 seconds, which negatively rendered performance. 

PEEK & Twitter Integration
Further, when we had to integrate the PEEK modules with twitter feed, we weren’t sure how the two different technologies would communicate to each other, especially allowing twitter API to access the camera, capture multiple layers of image and post it in twitter. Further, we weren’t sure how to resolve security constraints that are built within twitter so that the process would be more streamlined. Our experimentation continued in enabling big data analytics within VR/AR experience back to Sitecore experience database (xDB). We were unsure on how to provide the analytics-based 3D images that are coming via the Sitecore content manager.



244 – What work did you perform in the tax year to overcome those technological obstacles?   700 words max - 100 lines of 78 characters

Web AR/VR for Sitecore
During the months of January to December 2018, we continued the development of different versions to come up with logic on how the 3D components work within each other, managing 3D images and developing the associated algorithms.  We developed API components for navigation of 3D images within Sitecore and continued to advance the technology by developing APIs to perform natural feature detection functionality. We were successful in performing image recognition using marker-based detection AR. We achieved it by extending the initial design to have the marker stay on the 3D model in the camera. Similar to how we use bar codes to detect numbers, we build a marker, based on image that is recognizable, which has to be unique. We then extended Sitecore content author to attach the 3D marker. When the user focuses the camera on the marker, our API program would search for corresponding 3D object. This design approach expected us to store a number of 3D images as well as retrieve it very quickly based on the marker-detection algorithm applied on it. We faced major challenges with the performance of the entire solution coupled with storage limitations on saving markers for 3D images. We experimented prototyping with different caching technologies, preloading processes / technologies to arrive at a working model. 

We also experimented in developing a web portal that combines AR and VR in one experience. We initially prototyped using Apple and Google’s AR kits as R & D initiative and understand the design approach. We had to come up with a logic to track the location of a pointer (say door) and another pointer (say phone) in a room, and compare the distance, trigger activities. We attempted using Bluetooth based beacons blue tooth that are fixed in different locations. Each Bluetooth communicates with server and then with phones, to do trigger actions. We extended our Peek AR/VR libraries to so that IoT devices can be activated from Sitecore. At present we couldn’t have a stable and reliable design as the 4G network is not able to support the volume of the images along with speed. We will be continuing our experimentation in this area. We also prototyped towards enabling Big data using VR/ AR experience. In order to achieve this objective, we experimented how Sitecore experience DB that uses MongoDB collection database would handle the volume of the images and also linking them with the other components in Sitecore. We used MongoDB primarily for collecting data. Information about visitors and their interactions is written to MongoDB as flat JSON, which is then processed by an aggregation pipeline into a format that is used for reporting. Every component in xDB can be scaled content - xDB, allowed us to do personalization inside Sitecore that no one has ever done it so far. During the upgrade of Peek to Sitecore version 9 that contained new experience editor and XDB in MongoDB posed a number of unknowns. We had to re-model PEEK, extended and experimented new APIs with an attempt to re-design the integration points as the database had completely changed. We also encountered complex pipeline issues and getting the two systems working together again was extremely challenging.

Web AR Feature Detection

We continued experimentation in natural scene features stabilization and extend the tracking range of augmented reality (AR) pose-tracking systems. We extended computer vision methods to detect and track natural features in video images. We developed point and region features and properties of video images leading to its robust tracking. We developed multistage tracking algorithm to produce accurate motion estimates, and with continuous experimentation we were able to operate in a closed loop that stabilizes its performance and accuracy. We also extended the API to include newer mobile devices and browser versions.

Further, we developed and experimented with PC and mobile AR applications with small prototypes of marker Augmented Reality (AR) and interactive integration of virtual objects and integrated it with twitter. We point the phone on the marker of the backdrop and combine the AR screen with the photo taken using the camera. 

By fiscal year end, we were able to We present a prototype demonstrating the demonstrations of the benefits of using tracked natural features for AR applications that illustrate direct scene annotation, pose stabilization, and extendible tracking range. Our system represents a step toward integrating vision with graphics to produce robust wide-area augmented realities.

PEEK and Twitter Integration
The image was saved as file and we have to publish in twitter in real time. So, we experimented the twitter API, and security features and determine the design approach. We then modified Peek API to call our newly developed twitter app, that posts the image. The new Peek API accessed the camera in the phone, captured photo, and saved it as a file. It also accessed twitter API that contained modified privileges and post it to twitter. We had experiments around capturing multiple layers of the image, merging them together and send it to twitter to post the image. 


246 – What technological advancements were you trying to achieve? 	350 words max - 50 lines of 78 characters

In Project Peek initiative, we want to extend the capabilities of the Sitecore content management system to include the facets of Virtual and Augmented Reality. It is one of a kind, never attempted by anyone so far, and it will revolutionize the CMS world. There are no existing API or Web-kits that would allow Sitecore to have AR/VR integration. It provides an opportunity for companies to use VR/AR technological features within their matured Enterprise IT systems, Sitecore in this scope, without compromising its core look and feel, and improve experience and performance. Without using a mobile app or any similar tool, the user can initiate a session just with a web URL link in his desktop, laptop or any mobile device with ability to view 3-D components into the 3-D models, connect with navigation hotspots, edit and author contents within Sitecore. This will be the first time anywhere that we can perform natural feature detection in a web VR environment. We also wanted to integrate twitter and Peek so that we can provide a web VR experience in twitter. Further, we prototyped towards enabling Big data using VR/ AR experience. 


