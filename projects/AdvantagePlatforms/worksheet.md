
242 – What technological obstacles did you have to overcome? 350 words max – 50 lines of 78 characters








244 – What work did you perform in the tax year to overcome those technological obstacles?   700 words max - 100 lines of 78 characters


At the start of the experimental development process,
real industry data was required for this specific context of machine learning training.
It was ingested from various sources,
cleansed and refined and then our models were run to improve analysis.
This volume of data was attainable because of the test data we collected over time during previous experimentation and development.
A machine learning model was built for the test data to experimentally prove whether co-modeling could provide a score that was accurate or not.
We would require more data moving forward to improve the model,
so we built in a  backlog and drop process every 6 month’s worth of files into the learning machine model system for analysis,
which will increase the data set which the machine learning model can be advanced.
We needed to build the machine learning approach in such a way that it could call data,
take it and react to it,
with respect to the specific parameters of the mortgage industry.
We discovered the  most efficient model that produces the best suited results we were expecting,
we proved that real detail and the users own data were necessary components to the algorithm.


We next hypothesized development of an Options module,
where our Crystal Tools would be able to interface in an abstract manner to broker platforms to ingest data.
We found we needed to corrects common originator data errors and omissions by analyzing deal data via Natural Language Processing models and pattern analysis to determine intent for income and liability data.
We next analyzed bureau data to determine if originator supplied liabilities are consistent with calculated carry costs.
We then needed to devise a method to augments data with Purview data and plurality of data sources,
including FNF property valuation.
End to end result time was still slower than a minute.


As an attempt to speed up data ingestion process,
we tried to integrate a Voice AI model.
We extended some existing tools,
but we found that we still needed to ensure that any speed constricted conversation would not impact ingestion and overall processing time.
To attempt to mitigate this,
we developed a configurable rule engine,
which allowed us to abstract control of the rules to 3rd parties.
WE found that that costs a lot of processing time,
which was unacceptable.
So we developed a way to externalize data,
by developing an XML data structure which ran an Xpath expression over it to be able to manipulate input data.
In order to still advance to rule abstraction,
we found a way to re-architect am approach to expose Xpath expression to the front end.
This resulted in creating of rule policy procedures,
which were generic and dynamically changeable.


Next,
to improve results,
and also improve processing speed to less than a minute,
we thought we could develop tools to performs full cash flow analysis based on qualifying rates and liability payments that were input.
Our module was developed to runs data through risk simulations to determine compliance with underwriting rules.
We extended this to include the use of available cash flow to determine alternate results and options through the models,
which would create alternate outputs as end user options.

Prior to the end of the fiscal year,
we needed to focus on how to achieve better processing results,
and how we could automate the decision process.
We developed a method to analyze data from Triage decision from above,
which enhanced the overall results process with improved data intelligence.


We experimented within the Microsoft machine learning studio,
a cloud-based framework.
Machine learning models are only as good as the data used to train them,
consequently a key-goal of development of Crystal Tools was to allow generic data cleansing of inputted broker data first in order to supply a set of correct values to use as the input for data modelling.
Through running multiple experiments we saw the best results form a 2 Class boosted logistic regression model.
The R value evaluation becomes an important factor in relation to how we can improve the accuracy of the algorithms.
To improve the R value,
we next attempted to divide data to fields and parametrize the data.
We needed to find out what parameters were relevant to our context,
as this information was not available in the public domain.
Our experimental process will identify the routine way a broker will evaluate deal data.
We found that if we add specific parameters the modeling and ML determines that those specific parameters which are useful,
and we found that some of the usual parameters that humans have been using for the last twenty years don’t matter with respect to the rationale on accepting a result and offering a deal.
We realized that current parameters used only increased or decreased our accuracy of the results by .
1 or .
01,
so we could remove some of those legacy parameters to speed up our model.


We also realized that we could attempt to introduced an algorithm to calculate Deal Complexity Index.
We realized that industry might ‘know’ it’s a complicated deal,
but they don’t know why or how to quantify it.
Our approach would provide a measurement of the complexity of a potential result,
based on a number of factors,
not necessarily the deal’s potential risk.
It results in a factor of how difficult the deal will be to approve,
and how much work there will be to close the deal.
Deal Complexity Index introduces a  metric into the algorithm and processing for complexity and feasibility of the requested deal to be closed within a certain amount of time,
based on a plurality of factors.
This was not achievable prior to our experimental work.
More attempts to speed up the processing time would be done in the next fiscal period.



246 – What technological advancements were you trying to achieve? 	350 words max - 50 lines of 78 characters

Your response should focus on describing the improvements you made to the existing technology that lead to the creation of new or improved materials,
devices,
products,
or processes.

It is the advancement in the underlying technology that is important,
not how the work advanced your business practices.



Advantage Platforms’ Crystal Tools were created for the purpose of developing a technology layer that would overcome existing limitations in easily be able to plug into existing environments.
It would sit in front of a system and in-between broker systems where it would assess the deal in process and determine under-writer base.
Under-writers can now direct their attention only to the riskier deals that require their attention,
rather than study all deal types.
For this to be possible,
data handling and data correction and analysis techniques needed to be advanced beyond existing state.
The intent is that by the time the data was received,
it would be processed,
and a deal could be completed in near-real time.
We found that extending Machine Learning models specifically for the mortgage underwriting approach is helpful gathering data  from the external 3rd-party systems and matching  the most appropriate under-writer for the deal.
And we did this by developing model score algorithms to handle deal complexity.


To accommodate full automation,
interfacing with external mortgage systems was necessary to attain a certain offer result.
Advancements included closing deals as quick as possible: under 30 seconds is ideal,
a minute or more was too long.
We developed a language understanding model that allowed this to be possible by bringing things up to conversational speed.
The purpose is to generate options for the end user quickly based on ML algorithms.
Involving voice and text input was a key objective,
one of the goals of Crystal is to change the ways in which users interact with technology by moving away form traditional point and click GUI interfaces.
We learned it was successful in developing the interface where different language models were implemented with standing and execution models rather than the traditional methods.
We were able to achieve 1-2-second deal data processing times.
This changed the way underwriters would interact with users.
A chat box was developed to run over the distributive network so that a distributer can be provided recommendations when things are not working.
Deals could potentially then be restructured to offer more result offerings,
within a range of the original options,
building in predictive concessions.
Our Crystal tools ensure that no offer will be placed in front of an end user unless it suits their situation and works.
This allows flexible deal flow.
We further enhanced the process by developing opportunity modules.
A cash flow analysis has been built to analyze cash flow.
For example,
if free money is negative,
a deal is not calculated.
The system can assess positive cash flow,
and automatically generates other deal structures,
without exposing the lender to risk.

Current state of technology is that any deal is manually analyzed and scored for criteria.
We developed the approach to eliminate this interaction by applying Models to analyzing each criterion and consider if they are aligned with the intent.
The model determines if changes or additional input data is needed.


The key learning gained from this experimentation is in the development of machine learning powered option analysis tools,
which can reduce the turnaround time for mortgage analysis from days to minutes.
